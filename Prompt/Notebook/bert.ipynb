{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- #\n",
    "# NOTEBOOK MPI EXPERIMENT #\n",
    "# AUTHOR: XIAOYANG SONG   #\n",
    "# ----------------------- #\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tabulate import tabulate\n",
    "sys.path.append('../../')\n",
    "from MPI.mpi import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| outputs.last_hidden_state.shape: torch.Size([1, 8, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "ic| len(choice.input_ids[0,1:-1]): 7\n",
      "ic| tokenizer.decode(choice.input_ids[0]): '<s>(A). Very Inaccurate</s>'\n",
      "ic| tokenizer.decode(choice.input_ids[0][1:-1]): '(A). Very Inaccurate'\n",
      "ic| inputs: {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
      "             'input_ids': tensor([[    0, 31414, 20920,   623,     4, 50118, 33683,    35,    36,   250,\n",
      "                       322, 12178,    96,  7904, 23412,     2]])}\n",
      "ic| tokenizer.decode(inputs.input_ids[0][-8:-1]): ' (A). Very Inaccurate'\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaForCausalLM, AutoConfig\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# config = AutoConfig.from_pretrained(\"roberta-base\")\n",
    "# config.is_decoder = False\n",
    "# config.is_decoder=True\n",
    "\n",
    "# model = BertLMHeadModel.from_pretrained(\"bert-base-uncased\")\n",
    "model = RobertaForCausalLM.from_pretrained(\"roberta-base\")\n",
    "\n",
    "inputs = tokenizer(\"Hello Hello World.\\nAnswer: (A). Very Inaccurate\", return_tensors=\"pt\")\n",
    "choice = tokenizer(\"(A). Very Inaccurate\", return_tensors='pt', padding=True)\n",
    "ic(len(choice.input_ids[0,1:-1]))\n",
    "ic(tokenizer.decode(choice.input_ids[0]))\n",
    "ic(tokenizer.decode(choice.input_ids[0][1:-1]))\n",
    "# inputs = tokenizer(\"Hello, my dog is cute, I love dog\", return_tensors=\"pt\")\n",
    "ic(inputs)\n",
    "ic(tokenizer.decode(inputs.input_ids[0][-8:-1]))\n",
    "outputs = model(**inputs)\n",
    "\n",
    "prediction_logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| prediction_logits.squeeze().shape: torch.Size([16, 50265])\n",
      "ic| inputs.input_ids[0].shape: torch.Size([16])\n",
      "ic| prob.shape: torch.Size([16, 50265])\n",
      "ic| masked_prob.shape: torch.Size([16])\n",
      "ic| masked_prob: tensor([1.0000e+00, 9.9987e-01, 9.9966e-01, 9.9993e-01, 7.9664e-02, 3.7465e-12,\n",
      "                         9.9995e-01, 1.0000e+00, 9.9998e-01, 9.9992e-01, 9.9142e-01, 9.9996e-01,\n",
      "                         9.9976e-01, 9.9999e-01, 1.0000e+00, 9.2005e-01],\n",
      "                        grad_fn=<IndexBackward0>)\n",
      "ic| tokenizer.decode(idx): '<s>Hello Hello World</s></s>Answer: (A). Very Inaccurate</s>'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>Hello Hello World</s></s>Answer: (A). Very Inaccurate</s>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(prediction_logits.squeeze().shape)\n",
    "ic(inputs.input_ids[0].shape)\n",
    "prob = torch.softmax(prediction_logits.squeeze(), dim=-1)\n",
    "ic(prob.shape)\n",
    "masked_prob = prob[np.arange(inputs.input_ids[0].shape[0]), inputs.input_ids[0]]\n",
    "ic(masked_prob.shape)\n",
    "ic(masked_prob)\n",
    "idx = torch.max(prob, dim=-1)[1]\n",
    "ic(tokenizer.decode(idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
