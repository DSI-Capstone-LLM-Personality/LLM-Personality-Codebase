{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- #\n",
    "# NOTEBOOK MPI EXPERIMENT #\n",
    "# AUTHOR: XIAOYANG SONG   #\n",
    "# ----------------------- #\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tabulate import tabulate\n",
    "sys.path.append('../../')\n",
    "from MPI.mpi import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| outputs.last_hidden_state.shape: torch.Size([1, 8, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForPreTraining were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['sop_classifier.classifier.bias', 'sop_classifier.classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "ic| len(choice.input_ids[0,1:-1]): 7\n",
      "ic| tokenizer.decode(choice.input_ids[0]): '[CLS] (a). very inaccurate[SEP]'\n",
      "ic| tokenizer.decode(choice.input_ids[0][1:-1]): '(a). very inaccurate'\n",
      "ic| inputs: {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
      "             'input_ids': tensor([[    2, 10975, 10975,   126,     9,  1623,    45,    13,     5,    58,\n",
      "                         6,     9, 10975,   187,     3]]),\n",
      "             'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "ic| inputs.input_ids.shape: torch.Size([1, 15])\n",
      "ic| tokenizer.decode(inputs.input_ids[0][-8:-1]): '(a). hello!'\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaForCausalLM, AutoConfig, AlbertForPreTraining\n",
    "import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "# config = AutoConfig.from_pretrained(\"roberta-base\")\n",
    "# config.is_decoder = False\n",
    "# config.is_decoder=True\n",
    "\n",
    "# model = BertLMHeadModel.from_pretrained(\"bert-base-uncased\")\n",
    "# model = RobertaForCausalLM.from_pretrained(\"roberta-base\")\n",
    "model = AlbertForPreTraining.from_pretrained(\"albert-base-v2\")\n",
    "\n",
    "inputs = tokenizer(\"Hello Hello World.\\nAnswer: (A). Hello!\", return_tensors=\"pt\")\n",
    "choice = tokenizer(\"(A). Very Inaccurate\", return_tensors='pt')\n",
    "ic(len(choice.input_ids[0,1:-1]))\n",
    "ic(tokenizer.decode(choice.input_ids[0]))\n",
    "ic(tokenizer.decode(choice.input_ids[0][1:-1]))\n",
    "# inputs = tokenizer(\"Hello, my dog is cute, I love dog\", return_tensors=\"pt\")\n",
    "ic(inputs)\n",
    "ic(inputs.input_ids.shape)\n",
    "ic(tokenizer.decode(inputs.input_ids[0][-8:-1]))\n",
    "outputs = model(**inputs)\n",
    "# prediction_logits = outputs.logits\n",
    "prediction_logits = outputs.prediction_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in inputs.input_ids[0]:\n",
    "    ic(tokenizer.decode(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| prediction_logits.squeeze().shape: torch.Size([15, 30000])\n",
      "ic| inputs.input_ids[0].shape: torch.Size([15])\n",
      "ic| prob.shape: torch.Size([15, 30000])\n",
      "ic| masked_prob.shape: torch.Size([15])\n",
      "ic| masked_prob: tensor([4.7897e-09, 9.9919e-01, 9.8371e-01, 6.8068e-01, 9.4952e-01, 9.9545e-01,\n",
      "                         9.9918e-01, 8.3858e-01, 1.0000e+00, 9.6725e-01, 9.9983e-01, 9.3254e-01,\n",
      "                         9.4908e-01, 6.5884e-01, 3.2223e-04], grad_fn=<IndexBackward0>)\n",
      "ic| idx: tensor([  187, 10975, 10975,   126,     9,  1623,    45,    13,     5,    58,\n",
      "                     6,     9, 10975,   187,   154])\n",
      "ic| tokenizer.decode(idx): '! hello hello world. answer: (a). hello! your'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'! hello hello world. answer: (a). hello! your'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(prediction_logits.squeeze().shape)\n",
    "ic(inputs.input_ids[0].shape)\n",
    "prob = torch.softmax(prediction_logits.squeeze(), dim=-1)\n",
    "ic(prob.shape)\n",
    "masked_prob = prob[np.arange(inputs.input_ids[0].shape[0]), inputs.input_ids[0]]\n",
    "ic(masked_prob.shape)\n",
    "ic(masked_prob)\n",
    "idx = torch.max(prob, dim=-1)[1]\n",
    "ic(idx)\n",
    "ic(tokenizer.decode(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| eg.shape: torch.Size([50265])\n",
      "ic| tokenizer.decode([idx]): 'Hello'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eg = prob[1]\n",
    "ic(eg.shape)\n",
    "plt.plot(np.arange(len(eg)), eg.detach().cpu())\n",
    "idx = torch.argmax(eg)\n",
    "ic(tokenizer.decode([idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT (Constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import OpenAIGPTTokenizer, OpenAIGPTLMHeadModel\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(choice.input_ids[0,:]): 7\n",
      "ic| tokenizer.decode(choice.input_ids[0]): '(A). Very Inaccurate'\n",
      "ic| tokenizer.decode(choice.input_ids[0]): '(A). Very Inaccurate'\n",
      "ic| inputs: {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
      "             'input_ids': tensor([[15496, 18435,  2159,    13,   198, 33706,    25,   357,    32,   737,\n",
      "                      9576,   554,  4134, 15537]])}\n",
      "ic| tokenizer.decode(inputs.input_ids[0][-7:]): ' (A). Very Inaccurate'\n",
      "ic| prediction_logits.shape: torch.Size([1, 14, 50257])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 50257])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "inputs = tokenizer(\"Hello Hello World.\\nAnswer: (A). Very Inaccurate\", return_tensors=\"pt\")\n",
    "choice = tokenizer(\"(A). Very Inaccurate\", return_tensors='pt')\n",
    "ic(len(choice.input_ids[0,:]))\n",
    "ic(tokenizer.decode(choice.input_ids[0]))\n",
    "ic(tokenizer.decode(choice.input_ids[0]))\n",
    "# inputs = tokenizer(\"Hello, my dog is cute, I love dog\", return_tensors=\"pt\")\n",
    "ic(inputs)\n",
    "ic(tokenizer.decode(inputs.input_ids[0][-7:]))\n",
    "outputs = model(**inputs, labels=inputs.input_ids)\n",
    "\n",
    "prediction_logits = outputs.logits\n",
    "ic(prediction_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs.shape: torch.Size([1, 14, 50257])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 50257])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(prediction_logits, dim=-1)\n",
    "ic(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| eg.shape: torch.Size([50257])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Hello World.\n",
      "Answer: (A). Very Inaccurate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| idx: tensor(11)\n",
      "ic| tokenizer.decode([idx]): ','\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVRUlEQVR4nO3df5Bd5X3f8fdXu9pFvxBCWmxFgkgYpbYYPKm9wfHUST1mjAGnVjuBVjgzUV1myC+aH24mFc0MQ2imLW4nJBkzDZrBCXVaI0rrqcaWq+LgSTyJI2vFD4MAmUWAJVm2Vj+QEKAfq/32j3sk3b06Yq+WXd3l2fdrZmfPec5zzn2e1bmfe3TOc8+JzESSVK4ZnW6AJGlyGfSSVDiDXpIKZ9BLUuEMekkqnEEvSYVrK+gj4oaI2B4RgxGxtmb5z0fEExExHBE3tyxbExEvVj9rJqrhkqT2xFjj6COiC/g+8ElgF7AFuDUzn2uqswy4GPhdYENmPlqVXwoMAP1AAluBD2fmwQnviSSpVncbda4FBjNzB0BEPAysAk4HfWa+Ui0baVn3U8BjmXmgWv4YcAPwlXO92KJFi3LZsmXt90CSxNatW/dlZl/dsnaCfgmws2l+F/CRNl+7bt0lb7fCsmXLGBgYaHPzkiSAiHj1XMumxMXYiLg9IgYiYmBoaKjTzZGkorQT9LuBy5vml1Zl7Whr3cxcl5n9mdnf11f7Pw9J0ji1E/RbgBURsTwieoDVwIY2t78JuD4iFkTEAuD6qkySdIGMGfSZOQzcQSOgnwceycxtEXFPRHwGICJ+JiJ2AbcAD0TEtmrdA8C/p/FhsQW459SFWUnShTHm8MoLrb+/P70YK0nnJyK2ZmZ/3bIpcTFWkjR5DHpJKlwxQZ+ZfPXJXbx5fLjTTZGkKaWYoB949SC/s/5p7t6wrdNNkaQppZigP3KscST/48PHOtwSSZpaigl6SVI9g16SCmfQS1LhDHpJKpxBL0mFM+glqXDFBf3UunOPJHVeMUEfnW6AJE1RxQS9JKmeQS9JhTPoJalwBr0kFc6gl6TCGfSSVLjign6qPQNXkjqtmKCPcCS9JNUpJuglSfUMekkqnEEvSYUz6CWpcAa9JBXOoJekwhUT9A6ulKR6xQS9JKmeQS9JhTPoJalwBr0kFa6toI+IGyJie0QMRsTamuW9EbG+Wr45IpZV5TMj4qGIeCYino+IOye4/ZKkMYwZ9BHRBdwP3AisBG6NiJUt1W4DDmbmVcB9wL1V+S1Ab2ZeA3wY+JVTHwKSpAujnSP6a4HBzNyRmceBh4FVLXVWAQ9V048C10XjdpIJzImIbmAWcBw4PCEtPwfvUixJo7UT9EuAnU3zu6qy2jqZOQwcAhbSCP03gD3AD4D/kpkH3mGba3mXYkmqN9kXY68FTgI/ASwH/k1EXNlaKSJuj4iBiBgYGhqa5CZJ0vTSTtDvBi5vml9aldXWqU7TzAf2A58F/m9mnsjMvcDfAv2tL5CZ6zKzPzP7+/r6zr8XkqRzaifotwArImJ5RPQAq4ENLXU2AGuq6ZuBx7PxTL8fAJ8AiIg5wM8CL0xEwyVJ7Rkz6Ktz7ncAm4DngUcyc1tE3BMRn6mqPQgsjIhB4PPAqSGY9wNzI2IbjQ+MP8/M7010JyRJ59bdTqXM3AhsbCm7q2n6KI2hlK3rHakrlyRdOH4zVpIKV1zQJw6kl6RmxQR9eEd6SapVTNBLkuoZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhSsu6L0fvSSNVkzQez96SapXTNBLkuoZ9JJUOINekgpn0EtS4Qx6SSqcQS9JhSsu6B1HL0mjFRP0DqOXpHrFBL0kqZ5BL0mFM+glqXAGvSQVzqCXpMIZ9JJUuOKCPnEgvSQ1KyfoHUgvSbXKCXpJUi2DXpIKZ9BLUuEMekkqnEEvSYUz6CWpcG0FfUTcEBHbI2IwItbWLO+NiPXV8s0Rsaxp2Qcj4jsRsS0inomIiyaw/WfxfvSSNNqYQR8RXcD9wI3ASuDWiFjZUu024GBmXgXcB9xbrdsN/CXwq5l5NfBx4MSEtb65nQ6kl6Ra7RzRXwsMZuaOzDwOPAysaqmzCniomn4UuC4iArge+F5mPg2Qmfsz8+TENF2S1I52gn4JsLNpfldVVlsnM4eBQ8BC4KeAjIhNEfFERPxe3QtExO0RMRARA0NDQ+fbB0nS25jsi7HdwMeAX6p+/7OIuK61Umauy8z+zOzv6+ub5CZJ0vTSTtDvBi5vml9aldXWqc7Lzwf20zj6/5vM3JeZbwIbgQ+900ZLktrXTtBvAVZExPKI6AFWAxta6mwA1lTTNwOPZ2YCm4BrImJ29QHwj4HnJqbpkqR2dI9VITOHI+IOGqHdBXwpM7dFxD3AQGZuAB4EvhwRg8ABGh8GZObBiPgjGh8WCWzMzK9PUl8kSTXGDHqAzNxI47RLc9ldTdNHgVvOse5f0hhieUE4jF6SRivmm7HhMHpJqlVM0EuS6hn0klQ4g16SCmfQS1LhDHpJKpxBL0mFKy/oHUgvSaMUE/QOo5ekesUEvSSpnkEvSYUz6CWpcAa9JBXOoJekwhUX9On4SkkapZigD+9TLEm1igl6SVI9g16SCmfQS1LhDHpJKpxBL0mFM+glqXDFBX06jF6SRikm6B1GL0n1igl6SVI9g16SCmfQS1LhDHpJKpxBL0mFKy7oB149yMv73uh0MyRpyigu6AF+8b/+XaebIElTRjFB3zyM/vBbJzrWDkmaatoK+oi4ISK2R8RgRKytWd4bEeur5ZsjYlnL8isi4khE/O4EtVuS1KYxgz4iuoD7gRuBlcCtEbGypdptwMHMvAq4D7i3ZfkfAd94581tj3dBkKQz2jmivxYYzMwdmXkceBhY1VJnFfBQNf0ocF1Uz/aLiH8KvAxsm5AWS5LOSztBvwTY2TS/qyqrrZOZw8AhYGFEzAX+LfAH77ypkqTxmOyLsXcD92XmkberFBG3R8RARAwMDQ294xdNb2EpSad1t1FnN3B50/zSqqyuzq6I6AbmA/uBjwA3R8QXgEuAkYg4mplfbF45M9cB6wD6+/tNaUmaQO0E/RZgRUQspxHoq4HPttTZAKwBvgPcDDyejcPqnztVISLuBo60hrwkaXKNGfSZORwRdwCbgC7gS5m5LSLuAQYycwPwIPDliBgEDtD4MLigvB+9JNVr54iezNwIbGwpu6tp+ihwyxjbuHsc7RsXz/1I0hnFfDNWklTPoJekwhUZ9I6ulKQzigx6SdIZBr0kFc6gl6TCFRT0DqSXpDoFBb0kqY5BL0mFM+glqXAGvSQVzqCXpMIZ9JJUOINekgpXTNB7P3pJqldM0EuS6hn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXDFBL3D6CWpXjFBL0mqZ9BLUuEMekkqnEEvSYUz6CWpcAa9JBXOoJekwhUT9OEN6SWpVjFBL0mq11bQR8QNEbE9IgYjYm3N8t6IWF8t3xwRy6ryT0bE1oh4pvr9iQluvyRpDGMGfUR0AfcDNwIrgVsjYmVLtduAg5l5FXAfcG9Vvg/4J5l5DbAG+PJENVyS1J52juivBQYzc0dmHgceBla11FkFPFRNPwpcFxGRmU9m5g+r8m3ArIjonYiGS5La007QLwF2Ns3vqspq62TmMHAIWNhS5xeBJzLz2Piaen4OvnH8QryMJE153RfiRSLiahqnc64/x/LbgdsBrrjiigl5zRMnRyZkO5L0btfOEf1u4PKm+aVVWW2diOgG5gP7q/mlwFeBX87Ml+peIDPXZWZ/Zvb39fWdXw8kSW+rnaDfAqyIiOUR0QOsBja01NlA42IrwM3A45mZEXEJ8HVgbWb+7QS1uVbrKPqczBeTpHeRMYO+Oud+B7AJeB54JDO3RcQ9EfGZqtqDwMKIGAQ+D5wagnkHcBVwV0Q8Vf1cNuG9kCSdU1vn6DNzI7CxpeyupumjwC016/0h8IfvsI3j4vdkJanBb8ZKUuEMekkqnEEvSYUz6CWpcMUEfetdih1eKUkNxQS9JKlesUHv8EpJaig26CVJDcUGvefoJamh2KCXJDUUG/Seo5ekhmKD3lM3ktRQTNCHx/CSVKuYoG+VHtJLElBw0N/32Pc73QRJmhKKDfr1AzvHriRJ00CxQS9JajDoJalwBr0kFc6gl6TCFRP0rfejlyQ1FBP0kqR6Br0kFa6YoH/tzROdboIkTUnFBP2rB97odBMkaUoqJuglSfWKCfrhk2ffxexbL+ztQEskaWopJuhPnBw5q+xzf7GlAy2RpKmlmKDvnuFAekmqU0zQzzDoJalWMUF/Ls/vOcyeQ291uhmS1DHFB/2Nf/JtPvofH2fTth91uimSdE7P7j7EjqEjk7LttoI+Im6IiO0RMRgRa2uW90bE+mr55ohY1rTszqp8e0R8agLbfl6e+MFBnt9zmGd3H+pUEyTpnH7zK09y3zdfnJRtd49VISK6gPuBTwK7gC0RsSEzn2uqdhtwMDOviojVwL3Av4iIlcBq4GrgJ4BvRsRPZebJie7IWB746x088Nc7AHjpP9xEl+f0JU0TYwY9cC0wmJk7ACLiYWAV0Bz0q4C7q+lHgS9GRFTlD2fmMeDliBistvediWn++Lzv3208Pf1zKxbxrz+xgn/+QKNJf/G5n2HhnF7ed9kctv3wMHN7u5nd00VvdxdP7TzI9Svfy0gmJzOZOWMGETA8khx88zgL5/TSNSM4OZLMCIhx3FJzZCSJ81w3M9+2/shIerFamsbaCfolQPMDWHcBHzlXncwcjohDwMKq/O9b1l0y7ta+jUvn9IxrvW+/uI9vv7jv9Py//POyxt5fMnvmOe8DdGXfHHYMnbl1xGXzepnbe/YuceTYMHtfP3ZW+aVzerj4om5mRLBj35nt9M3rZej1Y/zkwtl0zQj2vHaUeRd1M6e3m5f3nX2riiWXzGJ2Txc/fO0tZvV0MX/WTI6eGOHIsWF6u2dw+OgJjp4YOd3moPHheuDIcfrm9Z6+RfVLVV+uumwumcmx4cY6vd2NM5SZjdtZn6p3alsRwbHhk+w88BYrLpvLSDa+fDeSnG7v+/rmEBEMnxzhxMlkVk8XAPuPHGPB7J5Rt8keSTg5kgyfHGFWTxdDrx+jb14vVK81MpKcGBmht7ur9t9lqslMEuDUdxID6g4bxnNgozN2HnyTq5fMn5RttxP0ky4ibgduB7jiiivGtY1PX7OYO3hyIptVhL65vaOCfuGcHva/cRyAlYsvZu/hYxw5NgzA+xdfzPxZM8/axvDJEb7x7NkXsz+weB6XzmkE2LHhEXa/9hazZnadDtb39c1lVk8XO4beoG9eLx9YPI/e7hm88KPXT29j0dwe+pctYPhksvPgm7x+dJiPLF/I15/Zw+yeLj521SL2HHqLJ37wWuM133sxSXJ8OPnm/h9zzdL5LJjdAwE7D7zF8ZMjrLhsLhGcDtjMRsh3dTWC6FTQf2DxxZBnvmx36u/0/vdefLp9L+97gw8unc+SS2YB8PrR4VF/o3zPXJ774WGuXtz0Bg14ae8RFs2dzbyLurmyr/HBcyrYT5wcYWbXu2wcRMCMiDOhD6OCn7O/mK7z9A/eM49bPrx0UrbdTtDvBi5vml9aldXV2RUR3cB8YH+b65KZ64B1AP39/ePaZSKCV/7Tp8ezqibZ/Z8dxzoT34wz2z6P9kxmO6QLpZ3Dii3AiohYHhE9NC6ubmipswFYU03fDDyemVmVr65G5SwHVgDfnZimS5LaMeYRfXXO/Q5gE9AFfCkzt0XEPcBAZm4AHgS+XF1sPUDjw4Cq3iM0LtwOA7/RiRE3kjSdRebUOrnW39+fAwMDnW6GJL2rRMTWzOyvW/YuuyIkSTpfBr0kFc6gl6TCGfSSVDiDXpIKN+VG3UTEEPDqO9jEImDfmLXKMd36C9Ovz9OtvzD9+jwR/f3JzOyrWzDlgv6dioiBcw0xKtF06y9Mvz5Pt/7C9OvzZPfXUzeSVDiDXpIKV2LQr+t0Ay6w6dZfmH59nm79henX50ntb3Hn6CVJo5V4RC9JalJM0I/1APOpLiK+FBF7I+LZprJLI+KxiHix+r2gKo+I+NOqr9+LiA81rbOmqv9iRKxpKv9wRDxTrfOn0eHHAUXE5RHxrYh4LiK2RcRvVeVF9jkiLoqI70bE01V//6AqXx4Rm6s2rq9uBU51a+/1VfnmiFjWtK07q/LtEfGppvIp+R6IiK6IeDIivlbNF9vniHil2ueeioiBqqzz+3Rmvut/aNw++SXgSqAHeBpY2el2nWcffh74EPBsU9kXgLXV9Frg3mr6JuAbNJ7t87PA5qr8UmBH9XtBNb2gWvbdqm5U697Y4f4uBj5UTc8Dvg+sLLXPVRvmVtMzgc1V2x4BVlflfwb8WjX968CfVdOrgfXV9Mpq/+4Fllf7fddUfg8Anwf+B/C1ar7YPgOvAItayjq+T3d8J5igP+5HgU1N83cCd3a6XePoxzJGB/12YHE1vRjYXk0/ANzaWg+4FXigqfyBqmwx8EJT+ah6U+EH+D/AJ6dDn4HZwBM0nr28D+iuyk/vxzSe//DRarq7qhet+/apelP1PUDjqXJ/BXwC+FrVh2L7TH3Qd3yfLuXUTd0DzCflIeQX2Hsyc081/SPgPdX0ufr7duW7asqnhOq/6P+QxlFusX2uTmE8BewFHqNxNPpaZg5XVZrbeLpf1fJDwELO/+/QaX8M/B4wUs0vpOw+J/D/ImJrNJ6FDVNgn54SDwfX2DIzI6K4IVIRMRf4X8BvZ+bh5lOOpfU5G09X++mIuAT4KvD+zrZockXELwB7M3NrRHy8w825UD6Wmbsj4jLgsYh4oXlhp/bpUo7o23oI+bvQjyNiMUD1e29Vfq7+vl350pryjoqImTRC/r9n5v+uiovuM0BmvgZ8i8aph0si4tQBV3MbT/erWj4f2M/5/x066R8Bn4mIV4CHaZy++RMK7nNm7q5+76XxYX4tU2Gf7vQ5vAk6L9ZN44LFcs5clLm60+0aRz+WMfoc/X9m9EWcL1TTn2b0RZzvVuWXAi/TuICzoJq+tFrWehHnpg73NYD/BvxxS3mRfQb6gEuq6VnAt4FfAP4noy9M/no1/RuMvjD5SDV9NaMvTO6gcVFySr8HgI9z5mJskX0G5gDzmqb/DrhhKuzTHd8BJvCPfBONkRsvAb/f6faMo/1fAfYAJ2ice7uNxvnJvwJeBL7Z9I8dwP1VX58B+pu286+Awernc03l/cCz1TpfpPqyXAf7+zEa5zO/BzxV/dxUap+BDwJPVv19FrirKr+yevMO0gjA3qr8omp+sFp+ZdO2fr/q03aaRl1M5fcAo4O+yD5X/Xq6+tl2qj1TYZ/2m7GSVLhSztFLks7BoJekwhn0klQ4g16SCmfQS1LhDHpJKpxBL0mFM+glqXD/H9ECmtwSoEI4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "print(\"Hello Hello World.\\nAnswer: (A). Very Inaccurate\")\n",
    "eg = probs[0][0]\n",
    "ic(eg.shape)\n",
    "plt.plot(np.arange(len(eg)), eg.detach().cpu())\n",
    "idx = torch.argmax(eg)\n",
    "ic(idx)\n",
    "ic(tokenizer.decode([idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| -loss: tensor(-3.9902, grad_fn=<NegBackward0>)\n",
      "ic| logits.shape: torch.Size([1, 6, 50257])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 50257])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits\n",
    "ic(-loss)\n",
    "ic(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| logits.shape: torch.Size([1, 6, 50257])\n",
      "ic| probs.shape: torch.Size([6])\n",
      "ic| torch.sum(torch.log(probs)): tensor(-53.3722, grad_fn=<SumBackward0>)\n",
      "ic| idxs: tensor([  11,  314, 1438,  318,  257,   13])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", I name is a.\n",
      "Hello, my dog is cute\n"
     ]
    }
   ],
   "source": [
    "ic(logits.shape)\n",
    "idxs = torch.argmax(logits.squeeze(), dim=-1)\n",
    "probs = torch.softmax(logits.squeeze(), dim=-1)[np.arange(6), inputs.input_ids[0]]\n",
    "ic(probs.shape)\n",
    "ic(torch.sum(torch.log(probs)))\n",
    "ic(idxs)\n",
    "print(tokenizer.decode(idxs))\n",
    "print(tokenizer.decode(inputs.input_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT (Open Vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a statement of you: \"You worry about things.\"\n",
      "Please choose from the following options to identify how accurately this statement describes you.\n",
      "Options: \n",
      "Very Accurate \n",
      "Moderately Accurate \n",
      "Neither Accurate Nor Inaccurate \n",
      "Moderately Inaccurate \n",
      "Very Inaccurate \n",
      "\n",
      "Answers: \n",
      "\n",
      "Very Accurate\n",
      "\n",
      "Moderately\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "from Model.language_model import *\n",
    "from Model.template import *\n",
    "# version = 'gpt2'\n",
    "version = 'gpt2-large'\n",
    "tokenizer = TOKENIZER['GPT2'].from_pretrained(version)\n",
    "model = MODEL['GPT2'].from_pretrained(version, pad_token_id=tokenizer.eos_token_id)\n",
    "with torch.no_grad():\n",
    "    # Text completion\n",
    "    item = \"worry about things\"\n",
    "    eg_q = MPI_TEMPLATE.format(item=item) + ordered_lst_to_str(MPI_DESC)\n",
    "    # # print(eg_q)\n",
    "    inputs = tokenizer(eg_q, return_tensors='pt')\n",
    "    input_ids = inputs.input_ids\n",
    "    response = model.generate(input_ids, do_sample=True, top_p=0.95, temperature=0.1,\n",
    "                                    num_return_sequences=1, early_stopping=True, max_new_tokens=10)\n",
    "    output = tokenizer.decode(response[0])\n",
    "print(output)\n",
    "print(len(response[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from util.utils import *\n",
    "from icecream import ic\n",
    "set_seed(2023)\n",
    "# Make sure to redirect to the correct path\n",
    "# I don't know why but it shows that Kiyan's api key is not correct.\n",
    "# openai.api_key = read_api_key(\"../../\", 'kiyan')\n",
    "openai.api_key = read_api_key(\"../../\", 'xysong')\n",
    "# eg_q = \"Please use a word to describe yourself.\"\n",
    "item = \"worry about things\"\n",
    "eg_q = MPI_TEMPLATE.format(item=item) + ordered_lst_to_str(MPI_DESC)\n",
    "response = openai.Completion.create(engine=\"text-davinci-002\", prompt=eg_q, temperature=0.1, max_tokens=100, top_p=0.95, logprobs=1)\n",
    "# print(response['choices'][0]['text'])\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a statement of you: \"You worry about things.\"\n",
      "Please choose from the following options to identify how accurately this statement describes you.\n",
      "Options: \n",
      "Very Accurate \n",
      "Moderately Accurate \n",
      "Neither Accurate Nor Inaccurate \n",
      "Moderately Inaccurate \n",
      "Very Inaccurate \n",
      "\n",
      "Answers: \n"
     ]
    }
   ],
   "source": [
    "from Model.language_model import *\n",
    "from Model.template import *\n",
    "item = \"worry about things\"\n",
    "eg_q = MPI_TEMPLATE.format(item=item) + ordered_lst_to_str(MPI_DESC)\n",
    "print(eg_q)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
