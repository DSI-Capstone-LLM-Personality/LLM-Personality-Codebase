{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- #\n",
    "# NOTEBOOK MPI EXPERIMENT #\n",
    "# AUTHOR: XIAOYANG SONG   #\n",
    "# ----------------------- #\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tabulate import tabulate\n",
    "sys.path.append('../../')\n",
    "from MPI.mpi import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| outputs.last_hidden_state.shape: torch.Size([1, 8, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "ic| len(choice.input_ids[0,1:-1]): 7\n",
      "ic| tokenizer.decode(choice.input_ids[0]): '<s>(A). Very Inaccurate</s>'\n",
      "ic| tokenizer.decode(choice.input_ids[0][1:-1]): '(A). Very Inaccurate'\n",
      "ic| inputs: {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
      "             'input_ids': tensor([[    0, 31414, 20920,   623,     4, 50118, 33683,    35,    36,   250,\n",
      "                       322, 12178,    96,  7904, 23412,     2]])}\n",
      "ic| tokenizer.decode(inputs.input_ids[0][-8:-1]): ' (A). Very Inaccurate'\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaForCausalLM, AutoConfig\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# config = AutoConfig.from_pretrained(\"roberta-base\")\n",
    "# config.is_decoder = False\n",
    "# config.is_decoder=True\n",
    "\n",
    "# model = BertLMHeadModel.from_pretrained(\"bert-base-uncased\")\n",
    "model = RobertaForCausalLM.from_pretrained(\"roberta-base\")\n",
    "\n",
    "inputs = tokenizer(\"Hello Hello World.\\nAnswer: (A). Very Inaccurate\", return_tensors=\"pt\")\n",
    "choice = tokenizer(\"(A). Very Inaccurate\", return_tensors='pt', padding=True)\n",
    "ic(len(choice.input_ids[0,1:-1]))\n",
    "ic(tokenizer.decode(choice.input_ids[0]))\n",
    "ic(tokenizer.decode(choice.input_ids[0][1:-1]))\n",
    "# inputs = tokenizer(\"Hello, my dog is cute, I love dog\", return_tensors=\"pt\")\n",
    "ic(inputs)\n",
    "ic(tokenizer.decode(inputs.input_ids[0][-8:-1]))\n",
    "outputs = model(**inputs)\n",
    "\n",
    "prediction_logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| prediction_logits.squeeze().shape: torch.Size([16, 50265])\n",
      "ic| inputs.input_ids[0].shape: torch.Size([16])\n",
      "ic| prob.shape: torch.Size([16, 50265])\n",
      "ic| masked_prob.shape: torch.Size([16])\n",
      "ic| masked_prob: tensor([1.0000e+00, 9.9987e-01, 9.9966e-01, 9.9993e-01, 7.9664e-02, 3.7465e-12,\n",
      "                         9.9995e-01, 1.0000e+00, 9.9998e-01, 9.9992e-01, 9.9142e-01, 9.9996e-01,\n",
      "                         9.9976e-01, 9.9999e-01, 1.0000e+00, 9.2005e-01],\n",
      "                        grad_fn=<IndexBackward0>)\n",
      "ic| tokenizer.decode(idx): '<s>Hello Hello World</s></s>Answer: (A). Very Inaccurate</s>'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>Hello Hello World</s></s>Answer: (A). Very Inaccurate</s>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(prediction_logits.squeeze().shape)\n",
    "ic(inputs.input_ids[0].shape)\n",
    "prob = torch.softmax(prediction_logits.squeeze(), dim=-1)\n",
    "ic(prob.shape)\n",
    "masked_prob = prob[np.arange(inputs.input_ids[0].shape[0]), inputs.input_ids[0]]\n",
    "ic(masked_prob.shape)\n",
    "ic(masked_prob)\n",
    "idx = torch.max(prob, dim=-1)[1]\n",
    "ic(tokenizer.decode(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(\"(A). choice\"): 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(len(\"(A). choice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 30522])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[0.0476, 0.3144, 0.9131, 0.9020, 1.0000, 0.9990, 1.0000, 0.9995, 1.0000,\n",
       "         0.9942, 0.9998, 0.5397, 0.9961]], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([[1012, 1012, 7592, 2088, 1012, 3437, 1024, 1006, 1037, 1012, 1012, 3601,\n",
       "         1012]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.softmax(prediction_logits, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = torch.softmax(prediction_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| logit.shape: torch.Size([5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = logit[0,-6:,:][np.arange(6-1), inputs.input_ids[0,-6:-1]]\n",
    "ic(logit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| logit: tensor([9.9998e-01, 6.3895e-03, 9.9984e-01, 9.9208e-01, 1.7561e-04],\n",
      "                  grad_fn=<IndexBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([9.9998e-01, 6.3895e-03, 9.9984e-01, 9.9208e-01, 1.7561e-04],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1006,  1037,  1007,  1012,  3601, 24949])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids[0,-7:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( a ). choice inaccurate'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([ 1006,  1037,  1007,  1012,  3601, 24949])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(torch.softmax(prediction_logits[0,6,:], dim=-1).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[0.0330, 0.1398, 0.5008, 0.9974]], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([[1012, 1012,  999, 1012]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.softmax(prediction_logits, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[0.0330, 0.1398, 0.5008, 0.9974]], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([[1012, 1012,  999, 1012]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.softmax(prediction_logits, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for dimension 1 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/xiaoyangsong/Desktop/DSI Capstone/LLM-Personality-Codebase/Prompt/Notebook/bert.ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/DSI%20Capstone/LLM-Personality-Codebase/Prompt/Notebook/bert.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xiaoyangsong/Desktop/DSI%20Capstone/LLM-Personality-Codebase/Prompt/Notebook/bert.ipynb#ch0000011?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(torch\u001b[39m.\u001b[39msoftmax(prediction_logits[\u001b[39m0\u001b[39;49m,\u001b[39m6\u001b[39;49m,:], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for dimension 1 with size 4"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(torch.softmax(prediction_logits[0,6,:], dim=-1).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = prediction_logits.squeeze().argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| idx: tensor([1012, 1012,  999, 1012])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1012, 1012,  999, 1012])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| tokenizer.decode(idx): '..!.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'..!.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(tokenizer.decode(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| tokenizer.decode([102]): '[SEP]'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(tokenizer.decode([102]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| tokenizer.decode([    0, 31414,     6,   127,  2335,    16, 11962,     2]): '<s>Hello, my dog is cute</s>'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>Hello, my dog is cute</s>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(tokenizer.decode([    0, 31414,     6,   127,  2335,    16, 11962,     2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
