{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from bert_mpi import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPI Experiment\n",
    "\n",
    "N | MEAN: 3.0 | STD: 0.0\n",
    "\n",
    "E | MEAN: 3.0 | STD: 0.0\n",
    "\n",
    "O | MEAN: 3.0 | STD: 0.0\n",
    "\n",
    "A | MEAN: 0.0 | STD: 3.464101552963257\n",
    "\n",
    "C | MEAN: 3.0 | STD: 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 120 multiple choice questions in total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.questions.shape: (120,)\n",
      "ic| Counter(col): Counter({'N': 24, 'E': 24, 'O': 24, 'A': 24, 'C': 24})\n",
      "ic| len(Counter(col)): 5\n",
      "ic| Counter(col): Counter({1: 65, -1: 55})\n",
      "ic| len(Counter(col)): 2\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]ic| pred: tensor(1)\n",
      "  1%|          | 1/120 [00:01<02:57,  1.49s/it]ic| pred: tensor(1)\n",
      "  2%|▏         | 2/120 [00:03<03:17,  1.68s/it]ic| pred: tensor(1)\n",
      "  2%|▎         | 3/120 [00:04<03:08,  1.61s/it]ic| pred: tensor(2)\n",
      "  3%|▎         | 4/120 [00:06<03:01,  1.56s/it]ic| pred: tensor(4)\n",
      "  4%|▍         | 5/120 [00:07<02:57,  1.54s/it]ic| pred: tensor(1)\n",
      "  5%|▌         | 6/120 [00:09<02:57,  1.56s/it]ic| pred: tensor(2)\n",
      "  6%|▌         | 7/120 [00:11<03:05,  1.64s/it]ic| pred: tensor(1)\n",
      "  7%|▋         | 8/120 [00:13<03:15,  1.75s/it]ic| pred: tensor(1)\n",
      "  8%|▊         | 9/120 [00:14<03:14,  1.75s/it]ic| pred: tensor(2)\n",
      "  8%|▊         | 10/120 [00:16<03:09,  1.72s/it]ic| pred: tensor(1)\n",
      "  9%|▉         | 11/120 [00:18<02:59,  1.65s/it]ic| pred: tensor(1)\n",
      " 10%|█         | 12/120 [00:19<02:56,  1.64s/it]ic| pred: tensor(1)\n",
      " 11%|█         | 13/120 [00:21<03:10,  1.78s/it]ic| pred: tensor(1)\n",
      " 12%|█▏        | 14/120 [00:23<03:13,  1.83s/it]ic| pred: tensor(2)\n",
      " 12%|█▎        | 15/120 [00:25<03:01,  1.73s/it]ic| pred: tensor(2)\n",
      " 13%|█▎        | 16/120 [00:27<03:04,  1.78s/it]ic| pred: tensor(1)\n",
      " 14%|█▍        | 17/120 [00:28<02:55,  1.70s/it]ic| pred: tensor(2)\n",
      " 15%|█▌        | 18/120 [00:30<03:04,  1.81s/it]ic| pred: tensor(1)\n",
      " 16%|█▌        | 19/120 [00:32<02:59,  1.78s/it]ic| pred: tensor(2)\n",
      " 17%|█▋        | 20/120 [00:34<02:53,  1.74s/it]ic| pred: tensor(1)\n",
      " 18%|█▊        | 21/120 [00:35<02:50,  1.72s/it]ic| pred: tensor(2)\n",
      " 18%|█▊        | 22/120 [00:37<02:38,  1.62s/it]ic| pred: tensor(1)\n",
      " 19%|█▉        | 23/120 [00:38<02:42,  1.67s/it]ic| pred: tensor(1)\n",
      " 20%|██        | 24/120 [00:40<02:45,  1.72s/it]ic| pred: tensor(2)\n",
      " 21%|██        | 25/120 [00:42<02:39,  1.68s/it]ic| pred: tensor(1)\n",
      " 22%|██▏       | 26/120 [00:44<02:40,  1.70s/it]ic| pred: tensor(1)\n",
      " 22%|██▎       | 27/120 [00:45<02:38,  1.70s/it]ic| pred: tensor(1)\n",
      " 23%|██▎       | 28/120 [00:47<02:42,  1.77s/it]ic| pred: tensor(3)\n",
      " 24%|██▍       | 29/120 [00:49<02:37,  1.73s/it]ic| pred: tensor(1)\n",
      " 25%|██▌       | 30/120 [00:51<02:37,  1.75s/it]ic| pred: tensor(1)\n",
      " 26%|██▌       | 31/120 [00:53<02:37,  1.77s/it]ic| pred: tensor(3)\n",
      " 27%|██▋       | 32/120 [00:56<03:20,  2.28s/it]ic| pred: tensor(2)\n",
      " 28%|██▊       | 33/120 [00:59<03:45,  2.59s/it]ic| pred: tensor(1)\n",
      " 28%|██▊       | 34/120 [01:03<04:12,  2.94s/it]ic| pred: tensor(1)\n",
      " 29%|██▉       | 35/120 [01:05<03:55,  2.77s/it]ic| pred: tensor(2)\n",
      " 30%|███       | 36/120 [01:07<03:20,  2.39s/it]ic| pred: tensor(1)\n",
      " 31%|███       | 37/120 [01:09<03:05,  2.23s/it]ic| pred: tensor(2)\n",
      " 32%|███▏      | 38/120 [01:11<02:52,  2.11s/it]ic| pred: tensor(2)\n",
      " 32%|███▎      | 39/120 [01:12<02:38,  1.95s/it]ic| pred: tensor(1)\n",
      " 33%|███▎      | 40/120 [01:14<02:30,  1.88s/it]ic| pred: tensor(2)\n",
      " 34%|███▍      | 41/120 [01:15<02:19,  1.77s/it]ic| pred: tensor(1)\n",
      " 35%|███▌      | 42/120 [01:18<02:29,  1.92s/it]ic| pred: tensor(3)\n",
      " 36%|███▌      | 43/120 [01:19<02:19,  1.81s/it]ic| pred: tensor(1)\n",
      " 37%|███▋      | 44/120 [01:21<02:20,  1.85s/it]ic| pred: tensor(1)\n",
      " 38%|███▊      | 45/120 [01:23<02:12,  1.77s/it]ic| pred: tensor(2)\n",
      " 38%|███▊      | 46/120 [01:24<02:07,  1.73s/it]ic| pred: tensor(1)\n",
      " 39%|███▉      | 47/120 [01:26<02:01,  1.67s/it]ic| pred: tensor(2)\n",
      " 40%|████      | 48/120 [01:28<02:00,  1.67s/it]ic| pred: tensor(1)\n",
      " 41%|████      | 49/120 [01:29<01:56,  1.64s/it]ic| pred: tensor(2)\n",
      " 42%|████▏     | 50/120 [01:32<02:21,  2.02s/it]ic| pred: tensor(1)\n",
      " 42%|████▎     | 51/120 [01:35<02:29,  2.16s/it]ic| pred: tensor(2)\n",
      " 43%|████▎     | 52/120 [01:36<02:18,  2.04s/it]ic| pred: tensor(2)\n",
      " 44%|████▍     | 53/120 [01:38<02:09,  1.93s/it]ic| pred: tensor(2)\n",
      " 45%|████▌     | 54/120 [01:40<01:59,  1.81s/it]ic| pred: tensor(2)\n",
      " 46%|████▌     | 55/120 [01:41<01:53,  1.74s/it]ic| pred: tensor(1)\n",
      " 47%|████▋     | 56/120 [01:43<01:47,  1.68s/it]ic| pred: tensor(2)\n",
      " 48%|████▊     | 57/120 [01:44<01:43,  1.64s/it]ic| pred: tensor(1)\n",
      " 48%|████▊     | 58/120 [01:47<01:57,  1.89s/it]ic| pred: tensor(1)\n",
      " 49%|████▉     | 59/120 [01:49<01:58,  1.95s/it]ic| pred: tensor(1)\n",
      " 50%|█████     | 60/120 [01:50<01:53,  1.89s/it]ic| pred: tensor(1)\n",
      " 51%|█████     | 61/120 [01:53<01:59,  2.02s/it]ic| pred: tensor(1)\n",
      " 52%|█████▏    | 62/120 [01:55<01:57,  2.03s/it]ic| pred: tensor(2)\n",
      " 52%|█████▎    | 63/120 [01:57<01:50,  1.93s/it]ic| pred: tensor(2)\n",
      " 53%|█████▎    | 64/120 [02:00<02:10,  2.33s/it]ic| pred: tensor(1)\n",
      " 54%|█████▍    | 65/120 [02:02<01:58,  2.15s/it]ic| pred: tensor(1)\n",
      " 55%|█████▌    | 66/120 [02:03<01:46,  1.98s/it]ic| pred: tensor(2)\n",
      " 56%|█████▌    | 67/120 [02:05<01:36,  1.81s/it]ic| pred: tensor(1)\n",
      " 57%|█████▋    | 68/120 [02:06<01:30,  1.73s/it]ic| pred: tensor(1)\n",
      " 57%|█████▊    | 69/120 [02:08<01:25,  1.68s/it]ic| pred: tensor(2)\n",
      " 58%|█████▊    | 70/120 [02:09<01:22,  1.66s/it]ic| pred: tensor(1)\n",
      " 59%|█████▉    | 71/120 [02:11<01:21,  1.67s/it]ic| pred: tensor(1)\n",
      " 60%|██████    | 72/120 [02:14<01:44,  2.17s/it]ic| pred: tensor(2)\n",
      " 61%|██████    | 73/120 [02:16<01:36,  2.06s/it]"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (/Users/xiaoyangsong/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1204175)",
      "at /Users/xiaoyangsong/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (/Users/xiaoyangsong/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1223212)",
      "at v.dispose (/Users/xiaoyangsong/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:1216694)",
      "at /Users/xiaoyangsong/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533674",
      "at t.swallowExceptions (/Users/xiaoyangsong/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:913059)",
      "at dispose (/Users/xiaoyangsong/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:533652)",
      "at t.RawSession.dispose (/Users/xiaoyangsong/.vscode/extensions/ms-toolsai.jupyter-2022.3.1000901801/out/extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "from bert_mpi import *\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-cased\")\n",
    "# model = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMultipleChoice.from_pretrained(\"bert-large-cased\")\n",
    "filename = \"mpi_small\"\n",
    "local_path = \"../Dataset/\" + f\"{filename}.csv\"\n",
    "mpi = MPI(local_path)\n",
    "mpi.run(tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N | MEAN: 4.0 | STD: 0.0\n",
      "E | MEAN: 4.0 | STD: 0.0\n",
      "O | MEAN: 4.0 | STD: 0.0\n",
      "A | MEAN: 0.0 | STD: 5.656854152679443\n",
      "C | MEAN: 4.0 | STD: 0.0\n"
     ]
    }
   ],
   "source": [
    "mpi.display_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.1304, 0.1141, 0.2970, 0.3135, 0.1450]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1311, 0.1123, 0.3007, 0.3137, 0.1422]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1324, 0.1136, 0.2948, 0.3141, 0.1452]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1312, 0.1107, 0.2988, 0.3150, 0.1443]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1344, 0.1135, 0.3029, 0.3065, 0.1428]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1316, 0.1116, 0.3069, 0.3080, 0.1418]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1339, 0.1125, 0.2932, 0.3172, 0.1433]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1306, 0.1106, 0.3049, 0.3135, 0.1404]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1303, 0.1102, 0.3102, 0.3121, 0.1372]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1340, 0.1164, 0.2930, 0.3135, 0.1432]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1274, 0.1115, 0.3086, 0.3110, 0.1414]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1359, 0.1135, 0.2896, 0.3119, 0.1491]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1310, 0.1107, 0.3046, 0.3083, 0.1455]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1311, 0.1130, 0.3002, 0.3141, 0.1415]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1317, 0.1122, 0.2973, 0.3145, 0.1443]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1271, 0.1095, 0.3138, 0.3120, 0.1377]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1297, 0.1156, 0.2939, 0.3184, 0.1423]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1314, 0.1146, 0.3007, 0.3124, 0.1408]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1378, 0.1155, 0.2948, 0.3025, 0.1493]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1334, 0.1138, 0.2858, 0.3199, 0.1471]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1323, 0.1140, 0.2952, 0.3186, 0.1399]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1337, 0.1127, 0.2896, 0.3162, 0.1479]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1350, 0.1123, 0.2975, 0.3137, 0.1415]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1280, 0.1085, 0.3112, 0.3088, 0.1435]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1286, 0.1112, 0.3076, 0.3108, 0.1418]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1323, 0.1128, 0.3010, 0.3101, 0.1438]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1292, 0.1125, 0.3013, 0.3154, 0.1415]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1376, 0.1111, 0.2951, 0.3159, 0.1404]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1316, 0.1063, 0.3114, 0.3115, 0.1391]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1308, 0.1133, 0.3071, 0.3104, 0.1384]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1315, 0.1132, 0.3039, 0.3079, 0.1436]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1286, 0.1099, 0.3110, 0.3129, 0.1376]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1348, 0.1168, 0.2828, 0.3194, 0.1462]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1274, 0.1080, 0.3113, 0.3148, 0.1386]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1289, 0.1116, 0.3080, 0.3126, 0.1389]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1325, 0.1139, 0.3057, 0.3055, 0.1424]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1322, 0.1174, 0.2989, 0.3106, 0.1409]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1284, 0.1134, 0.3090, 0.3095, 0.1397]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1331, 0.1171, 0.3013, 0.3055, 0.1431]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1304, 0.1136, 0.3075, 0.3086, 0.1399]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1294, 0.1088, 0.3043, 0.3145, 0.1430]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1301, 0.1120, 0.3062, 0.3112, 0.1405]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1302, 0.1142, 0.3023, 0.3104, 0.1429]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1295, 0.1119, 0.3072, 0.3099, 0.1415]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1290, 0.1095, 0.3094, 0.3097, 0.1424]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1300, 0.1114, 0.3094, 0.3072, 0.1420]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1278, 0.1127, 0.3066, 0.3139, 0.1390]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1321, 0.1120, 0.3075, 0.3103, 0.1379]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1300, 0.1121, 0.3090, 0.3064, 0.1424]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1286, 0.1170, 0.3101, 0.3062, 0.1381]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1308, 0.1124, 0.3040, 0.3143, 0.1385]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1340, 0.1128, 0.2925, 0.3117, 0.1489]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1324, 0.1111, 0.3093, 0.3081, 0.1392]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1318, 0.1116, 0.2961, 0.3174, 0.1431]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1380, 0.1192, 0.2766, 0.3173, 0.1489]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1307, 0.1135, 0.3060, 0.3080, 0.1418]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1330, 0.1135, 0.2941, 0.3160, 0.1434]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1256, 0.1080, 0.3159, 0.3131, 0.1373]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1308, 0.1105, 0.3069, 0.3119, 0.1399]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1296, 0.1101, 0.3080, 0.3101, 0.1422]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1275, 0.1120, 0.3110, 0.3100, 0.1395]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1332, 0.1151, 0.2982, 0.3092, 0.1442]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1285, 0.1097, 0.3064, 0.3171, 0.1383]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1296, 0.1116, 0.3038, 0.3149, 0.1401]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1313, 0.1145, 0.2991, 0.3129, 0.1421]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1351, 0.1150, 0.2941, 0.3092, 0.1466]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1276, 0.1117, 0.3086, 0.3138, 0.1384]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1285, 0.1147, 0.3043, 0.3164, 0.1361]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1273, 0.1103, 0.3088, 0.3138, 0.1398]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1354, 0.1163, 0.2925, 0.3110, 0.1447]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1308, 0.1130, 0.3036, 0.3126, 0.1401]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1317, 0.1126, 0.3000, 0.3121, 0.1436]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1295, 0.1111, 0.3119, 0.3099, 0.1376]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1271, 0.1080, 0.3143, 0.3121, 0.1385]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1297, 0.1111, 0.3051, 0.3099, 0.1442]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1301, 0.1112, 0.3064, 0.3133, 0.1389]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1384, 0.1172, 0.2840, 0.3146, 0.1459]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1308, 0.1102, 0.3048, 0.3121, 0.1421]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1326, 0.1125, 0.3045, 0.3060, 0.1444]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1334, 0.1135, 0.3006, 0.3107, 0.1418]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1293, 0.1123, 0.3071, 0.3123, 0.1390]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1305, 0.1100, 0.3020, 0.3130, 0.1446]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1304, 0.1095, 0.3098, 0.3107, 0.1395]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1307, 0.1077, 0.3063, 0.3155, 0.1397]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1347, 0.1157, 0.2938, 0.3079, 0.1479]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1281, 0.1099, 0.3042, 0.3174, 0.1405]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1316, 0.1099, 0.2862, 0.3266, 0.1457]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1354, 0.1087, 0.3032, 0.3151, 0.1376]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1287, 0.1124, 0.3117, 0.3073, 0.1399]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1317, 0.1148, 0.2980, 0.3107, 0.1449]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1301, 0.1123, 0.3081, 0.3114, 0.1380]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1322, 0.1140, 0.3034, 0.3094, 0.1411]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1312, 0.1149, 0.3049, 0.3098, 0.1392]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1272, 0.1080, 0.3099, 0.3130, 0.1419]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1326, 0.1125, 0.2990, 0.3137, 0.1421]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1307, 0.1160, 0.3039, 0.3073, 0.1420]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1317, 0.1137, 0.3008, 0.3096, 0.1443]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1368, 0.1159, 0.2904, 0.3153, 0.1417]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1311, 0.1128, 0.3033, 0.3115, 0.1413]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1362, 0.1203, 0.2837, 0.3145, 0.1454]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1318, 0.1119, 0.3010, 0.3128, 0.1426]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1332, 0.1136, 0.3038, 0.3074, 0.1419]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1290, 0.1094, 0.3133, 0.3128, 0.1354]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1301, 0.1141, 0.3036, 0.3124, 0.1398]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1299, 0.1105, 0.3058, 0.3106, 0.1432]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1291, 0.1096, 0.3117, 0.3111, 0.1384]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1291, 0.1115, 0.3076, 0.3123, 0.1395]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1260, 0.1089, 0.3136, 0.3154, 0.1361]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1337, 0.1177, 0.2973, 0.3080, 0.1433]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1390, 0.1191, 0.2867, 0.3078, 0.1474]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1328, 0.1121, 0.3052, 0.3066, 0.1433]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1321, 0.1124, 0.2961, 0.3131, 0.1464]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1301, 0.1109, 0.3107, 0.3104, 0.1379]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1325, 0.1128, 0.3027, 0.3111, 0.1410]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1336, 0.1182, 0.3040, 0.3028, 0.1414]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1353, 0.1161, 0.2928, 0.3092, 0.1466]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1332, 0.1147, 0.2991, 0.3105, 0.1425]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1326, 0.1103, 0.3055, 0.3096, 0.1420]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1315, 0.1124, 0.3075, 0.3082, 0.1404]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.1324, 0.1114, 0.3005, 0.3111, 0.1446]], grad_fn=<SoftmaxBackward0>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpi.probs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
