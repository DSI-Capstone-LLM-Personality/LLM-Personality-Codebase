{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Distribution Analysis\n",
    "\n",
    "Author: Xiaoyang Song & Morris Hsieh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Answer distribution of GPT3\n",
    "* Get the logs from `checkpoint/MPI-results/Open-Vocab/order-symmetry/text-davinci-002`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCEAN = 'OCEAN'\n",
    "GPT_ANSWER_TRAIT = {} # Key: OCEAN, Value (cnt): [<1>, <2>, <3>, <4>, <5>]\n",
    "\n",
    "# Read GPT Answer File\n",
    "with open(\n",
    "    './checkpoint/MPI-results/Open-Vocab/order-symmetry/text-davinci-002/syntactically-index/index-desc/[ocean_120]_[GPT3|text-davinci-002]_[syntactically-index]_[mpi-naive]_[original].txt'\n",
    "    ) as fr:\n",
    "    \n",
    "    all = fr.readlines()[106:]\n",
    "    for i in range(5): # Get 5 traits' answer distribution\n",
    "        shift = i * 25\n",
    "        scores_txt = all[shift].split(\"|\")[1:-1]\n",
    "        scores = [int(s) for s in scores_txt]\n",
    "\n",
    "        GPT_ANSWER_TRAIT[OCEAN[i]] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 4, 7, 9],\n",
       " [0, 0, 0, 15, 9],\n",
       " [1, 3, 1, 12, 7],\n",
       " [2, 0, 5, 10, 7],\n",
       " [2, 17, 3, 2, 0]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# traits, options: 5 x 5 matrix (OCEAN)\n",
    "GPT_ANSWER_MAT = [GPT_ANSWER_TRAIT[k] for k in GPT_ANSWER_TRAIT.keys()]\n",
    "GPT_ANSWER_MAT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Answer Distribution of IPIP120\n",
    "* Get the data from `Dataset/Human Data/IPIP120.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CASE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEC</th>\n",
       "      <th>MIN</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>...</th>\n",
       "      <th>I111</th>\n",
       "      <th>I112</th>\n",
       "      <th>I113</th>\n",
       "      <th>I114</th>\n",
       "      <th>I115</th>\n",
       "      <th>I116</th>\n",
       "      <th>I117</th>\n",
       "      <th>I118</th>\n",
       "      <th>I119</th>\n",
       "      <th>I120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  CASE  SEX   AGE   SEC   MIN  HOUR   DAY  MONTH   YEAR  ...  \\\n",
       "0           0   1.0  2.0  19.0   8.0  41.0  16.0  30.0    6.0  101.0  ...   \n",
       "1           1   2.0  2.0  22.0  24.0  45.0  16.0  30.0    6.0  101.0  ...   \n",
       "2           2   4.0  2.0  22.0   3.0  57.0  16.0  30.0    6.0  101.0  ...   \n",
       "3           3   5.0  2.0  22.0  44.0   4.0  17.0  30.0    6.0  101.0  ...   \n",
       "4           4   6.0  1.0  13.0  14.0   6.0  17.0  30.0    6.0  101.0  ...   \n",
       "\n",
       "  I111  I112  I113  I114  I115  I116  I117  I118  I119  I120  \n",
       "0  5.0   2.0   4.0   4.0   4.0   2.0   4.0   1.0   5.0   4.0  \n",
       "1  1.0   4.0   3.0   3.0   4.0   4.0   2.0   3.0   4.0   3.0  \n",
       "2  2.0   3.0   2.0   4.0   4.0   2.0   4.0   2.0   5.0   4.0  \n",
       "3  1.0   5.0   5.0   5.0   4.0   1.0   5.0   3.0   5.0   3.0  \n",
       "4  1.0   2.0   4.0   3.0   5.0   2.0   4.0   4.0   3.0   5.0  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "IPIP120_df = pd.read_csv(\"Dataset/Human Data/IPIP120.csv\")\n",
    "\n",
    "n_rows = IPIP120_df.shape[0]\n",
    "\n",
    "from util.human_ans_parser import get_item_key_map\n",
    "\n",
    "qt_df = pd.read_excel('Dataset/Human Data/IPIP-NEO-ItemKey.xls')\n",
    "item_key_map = get_item_key_map(qt_df, int(120))\n",
    "IPIP120_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "from geomloss import SamplesLoss\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import wasserstein_distance\n",
    "from icecream import ic\n",
    "from collections import Counter\n",
    "from itertools import filterfalse\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# OPT-125M-120\n",
    "LLM_OBS = {\n",
    "    'O': np.array([1, 5] * 12),\n",
    "    'C': np.array([1]* 11 + [5]*13),\n",
    "    'E': np.array([1]* 18 + [5]*6),\n",
    "    'A': np.array([1]* 7 + [5]*17),\n",
    "    'N': np.array([1]* 17 + [5]*7)\n",
    "}\n",
    "\n",
    "# OPT-350M-120\n",
    "\n",
    "LLM_OBS = {\n",
    "    'O': np.array([2, 4] * 12),\n",
    "    'C': np.array([2]* 11 + [4]*13),\n",
    "    'E': np.array([2]* 18 + [4]*6),\n",
    "    'A': np.array([2]* 7 + [4]*17),\n",
    "    'N': np.array([2]* 17 + [4]*7)\n",
    "}\n",
    "# Observation\n",
    "OBS = {}\n",
    "\n",
    "for trait in \"OCEAN\":\n",
    "    coi = list(filterfalse(lambda k: item_key_map[k][1] != trait, item_key_map))\n",
    "    OBS[trait] = np.array(IPIP120_df[coi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 619150/619150 [00:27<00:00, 22679.59it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 619150/619150 [00:26<00:00, 23141.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 619150/619150 [00:26<00:00, 23075.71it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 619150/619150 [00:28<00:00, 22004.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 619150/619150 [00:24<00:00, 24794.54it/s]\n"
     ]
    }
   ],
   "source": [
    "def calculate_scores(llm_obs, human_obs, disable_display=False):\n",
    "    return np.array([wasserstein_distance(llm_obs, obs) for obs in tqdm(human_obs, disable=disable_display)])\n",
    "\n",
    "LLM_SCORES = {}\n",
    "for trait in 'OCEAN':\n",
    "    LLM_SCORES[trait] = calculate_scores(LLM_OBS[trait], OBS[trait])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_to_obs(dist):\n",
    "    pass\n",
    "\n",
    "\n",
    "def obs_to_dist(obs):\n",
    "    dist = []\n",
    "    for x in tqdm(obs):\n",
    "        counter = Counter(x)\n",
    "        dist.append([counter[i] for i in range(1, 6, 1)])\n",
    "    return np.array(dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Distribution Wasserstein Distance Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:21<00:00, 47.33it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:20<00:00, 48.09it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:20<00:00, 49.86it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:19<00:00, 50.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:19<00:00, 50.16it/s]\n"
     ]
    }
   ],
   "source": [
    "N = len(IPIP120_df)\n",
    "n = 1000\n",
    "\n",
    "OBS_SCORES = {}\n",
    "# Choose a set of samples\n",
    "idx = np.random.choice(N, n, replace=False)\n",
    "# ic(idx)\n",
    "for trait in 'OCEAN':\n",
    "        trait_obs = OBS[trait]\n",
    "        sample_scores = []\n",
    "        # For efficiency, we only measure the upper diagonal pairs as Wasserstein distance is symmetric\n",
    "        for i in tqdm(range(n)):\n",
    "                # wass_score = []\n",
    "                for j in range(i, n, 1):\n",
    "                        sample_scores.append(wasserstein_distance(trait_obs[i], trait_obs[j]))\n",
    "                # sample_scores.append(wass_score)\n",
    "        sample_scores = np.array(sample_scores)\n",
    "        sample_scores_1d = sample_scores.reshape((-1,))\n",
    "        # Store\n",
    "        OBS_SCORES[trait] = sample_scores_1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(OBS_SCORES, \"human/HUMAN_OBS_SCORES.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For verification purpose only: this cell may take 20 minutes to rerun\n",
    "# Pick 10 human, compute their answer distributions with all others\n",
    "# We expect the distribution to be similar the one estimated by those 1000 samples before\n",
    "rand_human_idx = np.random.choice(N, 10, replace=False)\n",
    "HUMAN_VAL_SCORES = {}\n",
    "\n",
    "for trait in \"OCEAN\":\n",
    "    trait_obs = OBS[trait]\n",
    "    human_val_scores = []\n",
    "    for human in tqdm(rand_human_idx):\n",
    "        human_val_scores.append(calculate_scores(trait_obs[human].reshape((-1,)), trait_obs, True))\n",
    "    HUMAN_VAL_SCORES[trait] = np.array(human_val_scores).reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(HUMAN_VAL_SCORES, \"human/HUMAN_VAL.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_bins': 30,\n",
    "    'alpha': 0.3,\n",
    "    # 'c1': '#0000a7',\n",
    "    'c1': 'navy',\n",
    "    # 'c2': '#eecc16',\n",
    "\n",
    "    'c2': '#c1272d',\n",
    "    # 'c1': '#b3b3b3',\n",
    "    'trait': 'O',\n",
    "    'l1': 'Human',\n",
    "    # 'l2': 'OPT-125M',\n",
    "    'l2': 'Test',\n",
    "    # 'l2': 'Human Test',\n",
    "    # 'l2': 'OPT-13B',\n",
    "    'title': 'OPT-125M-Human'\n",
    "}\n",
    "\n",
    "\n",
    "def plot_distribution(dist1, dist2, c):\n",
    "    plt.hist(dist1, bins=c['num_bins'], density=True, alpha=c['alpha'], color=c['c1'], label=c['l1'])\n",
    "    plt.hist(dist2, bins=c['num_bins'], density=True, alpha=c['alpha'], color=c['c2'], label=c['l2'])\n",
    "    sns.kdeplot(dist1, linewidth=1, color=c['c1'], bw_adjust=2)\n",
    "    sns.kdeplot(dist2, linewidth=1, color=c['c2'], bw_adjust=2)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Wasserstein Distance\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f\"Pairwise Wasserstein Distance Distribution - Trait {c['trait']}\")\n",
    "    plt.savefig(f\"human/{c['l1'] + '-' + c['l2']}-{c['trait']}.jpg\", dpi=1200)\n",
    "    plt.close()\n",
    "\n",
    "for trait in 'OCEAN':\n",
    "    dist1 = OBS_SCORES[trait]\n",
    "    # dist2 = HUMAN_VAL_SCORES[trait].reshape((-1,))\n",
    "    dist2 = LLM_SCORES[trait]\n",
    "    config['trait'] = trait\n",
    "    plot_distribution(dist1, dist2, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_llm_distribution(dist, c):\n",
    "    plt.hist(dist, bins=c['num_bins'], density=True, alpha=c['alpha'], color=c['c2'], label=c['l2'])\n",
    "    sns.kdeplot(dist, linewidth=1, color=c['c2'], bw_adjust=2)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Wasserstein Distance\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f\"Pairwise Wasserstein Distance Distribution - Trait {c['trait']}\")\n",
    "    plt.savefig(f\"human/{c['l2']}-{c['trait']}.jpg\", dpi=1200)\n",
    "    plt.close()\n",
    "\n",
    "for trait in 'OCEAN':\n",
    "    dist = LLM_SCORES[trait]\n",
    "    config['trait'] = trait\n",
    "    plot_llm_distribution(dist, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "['81.6755%', '0.7730%', '0.2174%', '0.2174%', '0.2174%']\n",
      "C\n",
      "['73.3760%', '0.7504%', '0.2176%', '0.2176%', '0.2176%']\n",
      "E\n",
      "['72.8923%', '0.6701%', '0.2152%', '0.2152%', '0.2152%']\n",
      "A\n",
      "['81.3045%', '0.9293%', '0.2282%', '0.2282%', '0.2282%']\n",
      "N\n",
      "['67.6016%', '0.6072%', '0.2142%', '0.2142%', '0.2142%']\n"
     ]
    }
   ],
   "source": [
    "def find_percentage_below(scores, threshold):\n",
    "    mask = scores <= threshold\n",
    "    num = sum(mask)\n",
    "    p = num/ len(scores)\n",
    "    return mask, num, p\n",
    "for trait in 'OCEAN':\n",
    "    p_lst = []\n",
    "    for threshold in [1, 1e-1, 1e-2, 1e-3, 1e-4]:\n",
    "        mask, num,  p = find_percentage_below(OBS_SCORES[trait], threshold)\n",
    "        # ic(num)\n",
    "        # ic(f\"{p*100:.4f}%\")\n",
    "        p_lst.append(f\"{p*100:.4f}%\")\n",
    "    print(trait)\n",
    "    print(p_lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold: [1, 0.1, 0.001, 0.0001, 0.00001]\n",
    "O\n",
    "['81.6755%', '0.7730%', '0.2174%', '0.2174%', '0.2174%']\n",
    "C\n",
    "['73.3760%', '0.7504%', '0.2176%', '0.2176%', '0.2176%']\n",
    "E\n",
    "['72.8923%', '0.6701%', '0.2152%', '0.2152%', '0.2152%']\n",
    "A\n",
    "['81.3045%', '0.9293%', '0.2282%', '0.2282%', '0.2282%']\n",
    "N\n",
    "['67.6016%', '0.6072%', '0.2142%', '0.2142%', '0.2142%']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr): return arr / np.sum(arr, axis=1, keepdims=True)\n",
    "def entropy(arr):\n",
    "    tmp = arr\n",
    "    tmp[arr == 0] = 1\n",
    "    log_arr = np.emath.logn(5, tmp) # 5 classes so log base 5\n",
    "    return -np.sum(arr * log_arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 833.20it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 7108.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 9118.05it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 9098.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 10305.42it/s]\n",
      "ic| entropy(onehot): array([-0.])\n",
      "ic| entropy(uniform): array([1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'O': array([0.43067656]),\n",
       " 'C': array([0.42851664]),\n",
       " 'E': array([0.34939847]),\n",
       " 'A': array([0.37506091]),\n",
       " 'N': array([0.37506091])}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_DIST = {}\n",
    "\n",
    "for trait in 'OCEAN':\n",
    "    LLM_DIST[trait] = normalize(obs_to_dist(LLM_OBS[trait].reshape((1, -1))))\n",
    "\n",
    "LLM_ENTROPY = {}\n",
    "for trait in 'OCEAN':\n",
    "    LLM_ENTROPY[trait] = entropy(LLM_DIST[trait])\n",
    "\n",
    "onehot = np.array([[1, 0, 0, 0, 0]])\n",
    "uniform = np.array([[0.2, 0.2, 0.2, 0.20, 0.20]])\n",
    "ic(entropy(onehot))\n",
    "ic(entropy(uniform))\n",
    "LLM_ENTROPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 619150/619150 [00:06<00:00, 98459.68it/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 619150/619150 [00:05<00:00, 105703.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 619150/619150 [00:06<00:00, 92467.98it/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 619150/619150 [00:06<00:00, 96330.27it/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 619150/619150 [00:06<00:00, 92595.75it/s] \n"
     ]
    }
   ],
   "source": [
    "HUMAN_DIST = {}\n",
    "for trait in 'OCEAN':\n",
    "    HUMAN_DIST[trait] = normalize(obs_to_dist(OBS[trait]))\n",
    "\n",
    "HUMAN_ENTROPY = {}\n",
    "for trait in 'OCEAN':\n",
    "    HUMAN_ENTROPY[trait] = entropy(HUMAN_DIST[trait])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| HUMAN_DIST['O'].shape: (619150, 5)\n",
      "ic| HUMAN_ENTROPY['O'].shape: (619150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.70391133, 0.68665388, 0.83942405, ..., 0.73079042, 0.87710584,\n",
       "       0.76689374])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(HUMAN_DIST['O'].shape)\n",
    "ic(HUMAN_ENTROPY['O'].shape)\n",
    "HUMAN_ENTROPY['O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_bins': 30,\n",
    "    'alpha': 0.3,\n",
    "    'c1': 'navy',\n",
    "    # 'c2': '#eecc16',\n",
    "    'c2': '#c1272d',\n",
    "    'trait': 'O',\n",
    "    'l1': 'Human',\n",
    "    'l2': 'OPT-125M',\n",
    "    'title': 'OPT-125M-Human'\n",
    "}\n",
    "\n",
    "\n",
    "def plot_entropy(dist, llm_entropy, c):\n",
    "    plt.hist(dist, bins=c['num_bins'], density=True, alpha=c['alpha'], color=c['c1'], label=c['l1'])\n",
    "    plt.axvline(x=llm_entropy, color=c['c2'], linestyle='dashed', label=c['l2'])\n",
    "    sns.kdeplot(dist, linewidth=1, color=c['c1'], bw_adjust=2)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Entropy\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f\"Entropy Distribution - Trait {c['trait']}\")\n",
    "    plt.savefig(f\"human/Entropy-{c['l1'] + '-' + c['l2']}-{c['trait']}.jpg\", dpi=1000)\n",
    "    plt.close()\n",
    "\n",
    "for trait in 'OCEAN':\n",
    "    dist = HUMAN_ENTROPY[trait]\n",
    "    llm_entropy = LLM_ENTROPY[trait]\n",
    "    config['trait'] = trait\n",
    "    plot_entropy(dist, llm_entropy, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
