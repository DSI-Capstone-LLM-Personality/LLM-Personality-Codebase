{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from bert_mpi import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from bert_mpi import *\n",
    "from transformers import AutoTokenizer, BertForMultipleChoice, BertLMHeadModel\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertLMHeadModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| prob.shape: torch.Size([67, 30522])\n",
      "ic| torch.sum(torch.log(logits)): tensor(-6.6448, grad_fn=<SumBackward0>)\n",
      "ic| logits: tensor([0.0278, 0.2255, 0.9994, 0.9981, 0.9998, 0.9954, 0.9995, 1.0000, 0.9994,\n",
      "                    0.9979, 0.9877, 0.9978, 1.0000, 1.0000, 0.9717, 0.8981, 0.8578, 0.9991,\n",
      "                    0.9992, 0.9904, 0.9999, 0.8551, 1.0000, 0.9916, 0.9933, 0.9986, 0.9736,\n",
      "                    0.9981, 1.0000, 0.9947, 1.0000, 0.9998, 0.9999, 1.0000, 1.0000, 0.9971,\n",
      "                    0.9782, 1.0000, 0.9990, 1.0000, 0.9999, 0.9404, 0.9561, 1.0000, 0.9912,\n",
      "                    0.9978, 1.0000, 0.9983, 0.9956, 0.9996, 0.6608, 1.0000, 0.9995, 1.0000,\n",
      "                    1.0000, 0.9520, 0.7708, 1.0000, 0.9990, 0.9816, 1.0000, 0.9985, 0.9171,\n",
      "                    0.9871, 1.0000, 0.9685, 0.9895], grad_fn=<MaxBackward0>)\n",
      "ic| logits.shape: torch.Size([67])\n",
      "ic| loss: None\n"
     ]
    }
   ],
   "source": [
    "t1 = \"Make friends easily\"\n",
    "t2 = \"Trust other people\"\n",
    "t3 = \"Have difficulty imagining things\"\n",
    "t_lst = [t1, t2, t3]\n",
    "prompt_lst = [prepare_mpi_questions(t) for t in t_lst]\n",
    "# ic(prompt_lst[0])\n",
    "inputs = tokenizer(prompt_lst[0] +  \"A\", return_tensors=\"pt\")\n",
    "# outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "outputs = model(**inputs)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "# choice0 = \"It is eaten with a fork and a knife.\"\n",
    "# choice1 = \"It is eaten while held in the hand.\"\n",
    "# labels = torch.tensor(0).unsqueeze(0)  # choice0 is correct (according to Wikipedia ;)), batch size 1\n",
    "# statement = \"Trust others.\"\n",
    "t1 = \"Make friends easily\"\n",
    "t2 = \"Trust other people\"\n",
    "t3 = \"Have difficulty imagining things\"\n",
    "t_lst = [t1, t2, t3]\n",
    "prompt_lst = [prepare_mpi_questions(t) for t in t_lst]\n",
    "\n",
    "\n",
    "# prompt_lst = []\n",
    "for prompt in prompt_lst:\n",
    "    encoding = tokenizer([prompt]*5, ['A', 'B', 'C', 'D', 'E'], return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**{k: v.unsqueeze(0) for k, v in encoding.items()})  # batch size is 1\n",
    "\n",
    "    loss = outputs.loss\n",
    "    logits = outputs.logits\n",
    "    ic(logits)\n",
    "    print(MPI_IDX_TO_KEY[torch.argmax(logits.squeeze()).item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPI Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_mpi import *\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-large-cased\")\n",
    "# model = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n",
    "# model = BertForMultipleChoice.from_pretrained(\"bert-large-cased\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertLMHeadModel.from_pretrained(\"bert-base-uncased\")\n",
    "filename = \"mpi_small\"\n",
    "local_path = \"../Dataset/\" + f\"{filename}.csv\"\n",
    "\n",
    "MPI_OBJ_LST = []\n",
    "idx_lst = [(0, 120)]\n",
    "for (start, end) in idx_lst:\n",
    "    mpi = MPI(local_path, start, end)\n",
    "    mpi.run(tokenizer, model)\n",
    "    mpi.display_score()\n",
    "    MPI_OBJ_LST.append(mpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results (02/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 120 multiple choice questions in total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.questions.shape: (120,)\n",
      "ic| Counter(col): Counter({'N': 24, 'E': 24, 'O': 24, 'A': 24, 'C': 24})\n",
      "ic| len(Counter(col)): 5\n",
      "ic| Counter(col): Counter({1: 65, -1: 55})\n",
      "ic| len(Counter(col)): 2\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]ic| pred.item(): 2\n",
      "  1%|          | 1/120 [00:02<03:59,  2.01s/it]ic| pred.item(): 2\n",
      "  2%|▏         | 2/120 [00:03<03:25,  1.74s/it]ic| pred.item(): 2\n",
      "  2%|▎         | 3/120 [00:05<03:17,  1.69s/it]ic| pred.item(): 2\n",
      "  3%|▎         | 4/120 [00:07<03:26,  1.78s/it]ic| pred.item(): 2\n",
      "  4%|▍         | 5/120 [00:09<03:40,  1.92s/it]ic| pred.item(): 2\n",
      "  5%|▌         | 6/120 [00:10<03:29,  1.83s/it]ic| pred.item(): 2\n",
      "  6%|▌         | 7/120 [00:12<03:29,  1.86s/it]ic| pred.item(): 2\n",
      "  7%|▋         | 8/120 [00:16<04:32,  2.43s/it]ic| pred.item(): 2\n",
      "  8%|▊         | 9/120 [00:20<05:37,  3.04s/it]ic| pred.item(): 2\n",
      "  8%|▊         | 10/120 [00:22<05:01,  2.74s/it]ic| pred.item(): 2\n",
      "  9%|▉         | 11/120 [00:24<04:26,  2.45s/it]ic| pred.item(): 2\n",
      " 10%|█         | 12/120 [00:27<04:40,  2.59s/it]ic| pred.item(): 2\n",
      " 11%|█         | 13/120 [00:30<04:36,  2.59s/it]ic| pred.item(): 2\n",
      " 12%|█▏        | 14/120 [00:32<04:31,  2.56s/it]ic| pred.item(): 2\n",
      " 12%|█▎        | 15/120 [00:34<03:56,  2.25s/it]ic| pred.item(): 2\n",
      " 13%|█▎        | 16/120 [00:36<03:47,  2.19s/it]ic| pred.item(): 2\n",
      " 14%|█▍        | 17/120 [00:37<03:27,  2.01s/it]ic| pred.item(): 2\n",
      " 15%|█▌        | 18/120 [00:39<03:13,  1.89s/it]ic| pred.item(): 2\n",
      " 16%|█▌        | 19/120 [00:41<03:11,  1.90s/it]ic| pred.item(): 2\n",
      " 17%|█▋        | 20/120 [00:43<03:01,  1.81s/it]ic| pred.item(): 2\n",
      " 18%|█▊        | 21/120 [00:45<03:04,  1.86s/it]ic| pred.item(): 2\n",
      " 18%|█▊        | 22/120 [00:46<03:04,  1.88s/it]ic| pred.item(): 2\n",
      " 19%|█▉        | 23/120 [00:48<03:05,  1.91s/it]ic| pred.item(): 2\n",
      " 20%|██        | 24/120 [00:50<02:57,  1.85s/it]ic| pred.item(): 2\n",
      " 21%|██        | 25/120 [00:53<03:15,  2.06s/it]ic| pred.item(): 2\n",
      " 22%|██▏       | 26/120 [00:55<03:25,  2.18s/it]ic| pred.item(): 2\n",
      " 22%|██▎       | 27/120 [00:57<03:06,  2.01s/it]ic| pred.item(): 3\n",
      " 23%|██▎       | 28/120 [01:00<03:26,  2.25s/it]ic| pred.item(): 2\n",
      " 24%|██▍       | 29/120 [01:03<04:03,  2.68s/it]ic| pred.item(): 2\n",
      " 25%|██▌       | 30/120 [01:06<04:07,  2.76s/it]ic| pred.item(): 2\n",
      " 26%|██▌       | 31/120 [01:08<03:39,  2.46s/it]ic| pred.item(): 2\n",
      " 27%|██▋       | 32/120 [01:10<03:16,  2.23s/it]ic| pred.item(): 2\n",
      " 28%|██▊       | 33/120 [01:12<03:18,  2.29s/it]ic| pred.item(): 2\n",
      " 28%|██▊       | 34/120 [01:14<03:13,  2.25s/it]ic| pred.item(): 2\n",
      " 29%|██▉       | 35/120 [01:18<03:37,  2.56s/it]ic| pred.item(): 2\n",
      " 30%|███       | 36/120 [01:21<03:50,  2.75s/it]ic| pred.item(): 2\n",
      " 31%|███       | 37/120 [01:24<04:00,  2.89s/it]ic| pred.item(): 2\n",
      " 32%|███▏      | 38/120 [01:27<04:06,  3.01s/it]ic| pred.item(): 2\n",
      " 32%|███▎      | 39/120 [01:30<04:05,  3.03s/it]ic| pred.item(): 2\n",
      " 33%|███▎      | 40/120 [01:34<04:19,  3.25s/it]ic| pred.item(): 2\n",
      " 34%|███▍      | 41/120 [01:37<04:08,  3.14s/it]ic| pred.item(): 2\n",
      " 35%|███▌      | 42/120 [01:40<04:10,  3.21s/it]ic| pred.item(): 2\n",
      " 36%|███▌      | 43/120 [01:46<04:56,  3.85s/it]ic| pred.item(): 2\n",
      " 37%|███▋      | 44/120 [01:48<04:27,  3.53s/it]ic| pred.item(): 2\n",
      " 38%|███▊      | 45/120 [01:50<03:39,  2.92s/it]ic| pred.item(): 2\n",
      " 38%|███▊      | 46/120 [01:52<03:07,  2.54s/it]ic| pred.item(): 2\n",
      " 39%|███▉      | 47/120 [01:53<02:48,  2.30s/it]ic| pred.item(): 2\n",
      " 40%|████      | 48/120 [01:56<03:00,  2.50s/it]ic| pred.item(): 2\n",
      " 41%|████      | 49/120 [01:59<02:55,  2.47s/it]ic| pred.item(): 2\n",
      " 42%|████▏     | 50/120 [02:03<03:37,  3.11s/it]ic| pred.item(): 2\n",
      " 42%|████▎     | 51/120 [02:07<03:45,  3.27s/it]ic| pred.item(): 2\n",
      " 43%|████▎     | 52/120 [02:10<03:44,  3.30s/it]ic| pred.item(): 2\n",
      " 44%|████▍     | 53/120 [02:13<03:22,  3.02s/it]ic| pred.item(): 2\n",
      " 45%|████▌     | 54/120 [02:15<03:04,  2.80s/it]ic| pred.item(): 2\n",
      " 46%|████▌     | 55/120 [02:17<02:51,  2.64s/it]ic| pred.item(): 2\n",
      " 47%|████▋     | 56/120 [02:20<02:41,  2.53s/it]ic| pred.item(): 2\n",
      " 48%|████▊     | 57/120 [02:22<02:44,  2.62s/it]ic| pred.item(): 2\n",
      " 48%|████▊     | 58/120 [02:26<02:56,  2.84s/it]ic| pred.item(): 2\n",
      " 49%|████▉     | 59/120 [02:29<03:03,  3.00s/it]ic| pred.item(): 2\n",
      " 50%|█████     | 60/120 [02:33<03:12,  3.20s/it]ic| pred.item(): 2\n",
      " 51%|█████     | 61/120 [02:36<03:05,  3.14s/it]ic| pred.item(): 2\n",
      " 52%|█████▏    | 62/120 [02:39<03:01,  3.13s/it]ic| pred.item(): 2\n",
      " 52%|█████▎    | 63/120 [02:42<02:55,  3.08s/it]ic| pred.item(): 2\n",
      " 53%|█████▎    | 64/120 [02:45<02:57,  3.17s/it]ic| pred.item(): 2\n",
      " 54%|█████▍    | 65/120 [02:49<03:00,  3.29s/it]ic| pred.item(): 2\n",
      " 55%|█████▌    | 66/120 [02:53<03:05,  3.43s/it]ic| pred.item(): 2\n",
      " 56%|█████▌    | 67/120 [02:56<03:02,  3.45s/it]ic| pred.item(): 2\n",
      " 57%|█████▋    | 68/120 [02:59<02:53,  3.34s/it]ic| pred.item(): 2\n",
      " 57%|█████▊    | 69/120 [03:03<02:55,  3.44s/it]ic| pred.item(): 2\n",
      " 58%|█████▊    | 70/120 [03:06<02:49,  3.40s/it]ic| pred.item(): 2\n",
      " 59%|█████▉    | 71/120 [03:10<02:50,  3.48s/it]ic| pred.item(): 2\n",
      " 60%|██████    | 72/120 [03:13<02:48,  3.52s/it]ic| pred.item(): 2\n",
      " 61%|██████    | 73/120 [03:16<02:32,  3.26s/it]ic| pred.item(): 2\n",
      " 62%|██████▏   | 74/120 [03:18<02:08,  2.80s/it]ic| pred.item(): 2\n",
      " 62%|██████▎   | 75/120 [03:19<01:49,  2.44s/it]ic| pred.item(): 2\n",
      " 63%|██████▎   | 76/120 [03:21<01:36,  2.20s/it]ic| pred.item(): 2\n",
      " 64%|██████▍   | 77/120 [03:23<01:27,  2.04s/it]ic| pred.item(): 2\n",
      " 65%|██████▌   | 78/120 [03:25<01:24,  2.01s/it]ic| pred.item(): 2\n",
      " 66%|██████▌   | 79/120 [03:34<02:49,  4.14s/it]ic| pred.item(): 2\n",
      " 67%|██████▋   | 80/120 [03:38<02:52,  4.32s/it]ic| pred.item(): 2\n",
      " 68%|██████▊   | 81/120 [03:40<02:17,  3.53s/it]ic| pred.item(): 2\n",
      " 68%|██████▊   | 82/120 [03:42<01:56,  3.06s/it]ic| pred.item(): 2\n",
      " 69%|██████▉   | 83/120 [03:45<01:48,  2.93s/it]ic| pred.item(): 2\n",
      " 70%|███████   | 84/120 [03:46<01:32,  2.57s/it]ic| pred.item(): 2\n",
      " 71%|███████   | 85/120 [03:48<01:20,  2.30s/it]ic| pred.item(): 2\n",
      " 72%|███████▏  | 86/120 [03:51<01:25,  2.52s/it]ic| pred.item(): 2\n",
      " 72%|███████▎  | 87/120 [03:55<01:33,  2.83s/it]ic| pred.item(): 3\n",
      " 73%|███████▎  | 88/120 [03:58<01:32,  2.89s/it]ic| pred.item(): 2\n",
      " 74%|███████▍  | 89/120 [04:00<01:19,  2.57s/it]ic| pred.item(): 2\n",
      " 75%|███████▌  | 90/120 [04:01<01:10,  2.34s/it]ic| pred.item(): 2\n",
      " 76%|███████▌  | 91/120 [04:03<01:02,  2.16s/it]ic| pred.item(): 2\n",
      " 77%|███████▋  | 92/120 [04:05<00:56,  2.01s/it]ic| pred.item(): 2\n",
      " 78%|███████▊  | 93/120 [04:07<00:54,  2.01s/it]ic| pred.item(): 2\n",
      " 78%|███████▊  | 94/120 [04:09<00:52,  2.03s/it]ic| pred.item(): 2\n",
      " 79%|███████▉  | 95/120 [04:13<01:08,  2.72s/it]ic| pred.item(): 2\n",
      " 80%|████████  | 96/120 [04:17<01:11,  2.98s/it]ic| pred.item(): 2\n",
      " 81%|████████  | 97/120 [04:20<01:10,  3.04s/it]ic| pred.item(): 2\n",
      " 82%|████████▏ | 98/120 [04:23<01:08,  3.12s/it]ic| pred.item(): 2\n",
      " 82%|████████▎ | 99/120 [04:27<01:07,  3.20s/it]ic| pred.item(): 2\n",
      " 83%|████████▎ | 100/120 [04:30<01:05,  3.29s/it]ic| pred.item(): 2\n",
      " 84%|████████▍ | 101/120 [04:34<01:05,  3.46s/it]ic| pred.item(): 2\n",
      " 85%|████████▌ | 102/120 [04:38<01:03,  3.52s/it]ic| pred.item(): 2\n",
      " 86%|████████▌ | 103/120 [04:41<01:01,  3.61s/it]ic| pred.item(): 2\n",
      " 87%|████████▋ | 104/120 [04:47<01:06,  4.14s/it]ic| pred.item(): 2\n",
      " 88%|████████▊ | 105/120 [04:50<00:57,  3.84s/it]ic| pred.item(): 2\n",
      " 88%|████████▊ | 106/120 [04:54<00:52,  3.78s/it]ic| pred.item(): 2\n",
      " 89%|████████▉ | 107/120 [04:57<00:46,  3.59s/it]ic| pred.item(): 2\n",
      " 90%|█████████ | 108/120 [05:00<00:42,  3.56s/it]ic| pred.item(): 2\n",
      " 91%|█████████ | 109/120 [05:04<00:40,  3.65s/it]ic| pred.item(): 2\n",
      " 92%|█████████▏| 110/120 [05:08<00:35,  3.58s/it]ic| pred.item(): 2\n",
      " 92%|█████████▎| 111/120 [05:11<00:32,  3.63s/it]ic| pred.item(): 2\n",
      " 93%|█████████▎| 112/120 [05:15<00:28,  3.53s/it]ic| pred.item(): 2\n",
      " 94%|█████████▍| 113/120 [05:18<00:24,  3.44s/it]ic| pred.item(): 2\n",
      " 95%|█████████▌| 114/120 [05:22<00:21,  3.64s/it]ic| pred.item(): 2\n",
      " 96%|█████████▌| 115/120 [05:25<00:17,  3.50s/it]ic| pred.item(): 2\n",
      " 97%|█████████▋| 116/120 [05:28<00:13,  3.36s/it]ic| pred.item(): 2\n",
      " 98%|█████████▊| 117/120 [05:32<00:10,  3.55s/it]ic| pred.item(): 2\n",
      " 98%|█████████▊| 118/120 [05:36<00:07,  3.57s/it]ic| pred.item(): 2\n",
      " 99%|█████████▉| 119/120 [05:39<00:03,  3.58s/it]ic| pred.item(): 2\n",
      "100%|██████████| 120/120 [05:43<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N | MEAN: 1.25 | STD: 2.7858338356018066\n",
      "E | MEAN: 1.5 | STD: 2.6539552211761475\n",
      "O | MEAN: 0.0 | STD: 2.9927449226379395\n",
      "A | MEAN: -1.25 | STD: 2.7858338356018066\n",
      "C | MEAN: -0.25 | STD: 3.0538642406463623\n"
     ]
    }
   ],
   "source": [
    "from bert_mpi import *\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-large-cased\")\n",
    "# model = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n",
    "# model = BertForMultipleChoice.from_pretrained(\"bert-large-cased\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model = BertForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertLMHeadModel.from_pretrained(\"bert-base-uncased\")\n",
    "filename = \"mpi_small\"\n",
    "local_path = \"../Dataset/\" + f\"{filename}.csv\"\n",
    "\n",
    "MPI_OBJ_LST = []\n",
    "idx_lst = [(0, 120)]\n",
    "for (start, end) in idx_lst:\n",
    "    mpi = MPI(local_path, start, end)\n",
    "    mpi.run(tokenizer, model)\n",
    "    mpi.display_score()\n",
    "    MPI_OBJ_LST.append(mpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 64, -3: 54, 2: 1, -2: 1})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(np.array(mpi.scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N | MEAN: 1.25 | STD: 2.7858338356018066\n",
    "\n",
    "E | MEAN: 1.5 | STD: 2.6539552211761475\n",
    "\n",
    "O | MEAN: 0.0 | STD: 2.9927449226379395\n",
    "\n",
    "A | MEAN: -1.25 | STD: 2.7858338356018066\n",
    "\n",
    "C | MEAN: -0.25 | STD: 3.0538642406463623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
